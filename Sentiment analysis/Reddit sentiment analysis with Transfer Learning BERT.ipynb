{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0510_50 epoch_Reddit sentiment analysis with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bead08073664779988f300d0731297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98196384fe564ba1a0992fd9d7569669",
              "IPY_MODEL_aa2945a62aa940389075c3c38f374144",
              "IPY_MODEL_9a82568195a745088d2de0a3ad363e32"
            ],
            "layout": "IPY_MODEL_e37a0181eb0749b8ba50734f731a7784"
          }
        },
        "98196384fe564ba1a0992fd9d7569669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc4e081adb914f6da57bd1a481ca821f",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7aa5b0023d4890a8febfcd0f5bdbde",
            "value": "Downloading: 100%"
          }
        },
        "aa2945a62aa940389075c3c38f374144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8313b33bb0f04adaa999ee42931a9fcc",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f5bf83183d840ff8d190df85acb2be8",
            "value": 213450
          }
        },
        "9a82568195a745088d2de0a3ad363e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19eb518f9c39499f88c8dcde3a53e242",
            "placeholder": "​",
            "style": "IPY_MODEL_37044ae54e7244eaa51926329f5c9182",
            "value": " 208k/208k [00:00&lt;00:00, 211kB/s]"
          }
        },
        "e37a0181eb0749b8ba50734f731a7784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4e081adb914f6da57bd1a481ca821f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7aa5b0023d4890a8febfcd0f5bdbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8313b33bb0f04adaa999ee42931a9fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5bf83183d840ff8d190df85acb2be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19eb518f9c39499f88c8dcde3a53e242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37044ae54e7244eaa51926329f5c9182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0afb9732fe9475f9c8179128bd7fad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b465ce27c464d31ae224484ae51be2d",
              "IPY_MODEL_169a46af9a934b0a9ec3454ebe15c982",
              "IPY_MODEL_701fb6ce990f4c719ad5be66d5f0f1f6"
            ],
            "layout": "IPY_MODEL_ea2a6e4fef6b4a489036e9b5459957d5"
          }
        },
        "6b465ce27c464d31ae224484ae51be2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e1e42081c4429db1c01910da68fef9",
            "placeholder": "​",
            "style": "IPY_MODEL_58282b987fb6469d8b802a0477ad3083",
            "value": "Downloading: 100%"
          }
        },
        "169a46af9a934b0a9ec3454ebe15c982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1673534369b84e7d8c7ce2da003578e5",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_777d36f0d53a4cb5aed8a1f154fe2d79",
            "value": 29
          }
        },
        "701fb6ce990f4c719ad5be66d5f0f1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4e15063823493b9dae95bf72872a71",
            "placeholder": "​",
            "style": "IPY_MODEL_3324f1e1de644438bff2847c91513422",
            "value": " 29.0/29.0 [00:00&lt;00:00, 335B/s]"
          }
        },
        "ea2a6e4fef6b4a489036e9b5459957d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e1e42081c4429db1c01910da68fef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58282b987fb6469d8b802a0477ad3083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1673534369b84e7d8c7ce2da003578e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777d36f0d53a4cb5aed8a1f154fe2d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d4e15063823493b9dae95bf72872a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3324f1e1de644438bff2847c91513422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20df4dc2ee3b4727a82e2aac4dc7a579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e59ec612f7a48f4876d510cda1f7a23",
              "IPY_MODEL_56f8aa5f7a7549dabe0d82d90414b73a",
              "IPY_MODEL_7219cc54ff1c4c2fb210a93d3de73fba"
            ],
            "layout": "IPY_MODEL_9da241bebb0646199eac0dd2704c94b1"
          }
        },
        "0e59ec612f7a48f4876d510cda1f7a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86bfc3ec61e844699ea2d3969e487b16",
            "placeholder": "​",
            "style": "IPY_MODEL_42a683fcf1444fd5be0aca23f10a43fe",
            "value": "Downloading: 100%"
          }
        },
        "56f8aa5f7a7549dabe0d82d90414b73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851afc2618bf426ebba2444a9fb32063",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e24bc2f094d429faccc6911581b8167",
            "value": 570
          }
        },
        "7219cc54ff1c4c2fb210a93d3de73fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08cdcc50f37748f99bb03b77931aa2d0",
            "placeholder": "​",
            "style": "IPY_MODEL_8d3b427a7dbd473da9dc829d1cbbdacb",
            "value": " 570/570 [00:00&lt;00:00, 5.59kB/s]"
          }
        },
        "9da241bebb0646199eac0dd2704c94b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bfc3ec61e844699ea2d3969e487b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a683fcf1444fd5be0aca23f10a43fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "851afc2618bf426ebba2444a9fb32063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e24bc2f094d429faccc6911581b8167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08cdcc50f37748f99bb03b77931aa2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3b427a7dbd473da9dc829d1cbbdacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cee96ef883d436ea8d984aa1126f8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d880ad38ac7142f0b8f2b23b0f688ab1",
              "IPY_MODEL_3999fba07e2242c3a6be2913d2eec86b",
              "IPY_MODEL_40b705d35f564a2fb6a0efa0224a18ec"
            ],
            "layout": "IPY_MODEL_d376626d7f0e45138d78d2fa01b0b96f"
          }
        },
        "d880ad38ac7142f0b8f2b23b0f688ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed3175ca09414480b1f1c48f48c781f4",
            "placeholder": "​",
            "style": "IPY_MODEL_24b8649914fe41adad872b50abaf6ef9",
            "value": "Downloading: 100%"
          }
        },
        "3999fba07e2242c3a6be2913d2eec86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87b47d5d4de4e1e8a62c2925b5579b2",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cce9bee1bcf8415eab95865aa153dbe5",
            "value": 435779157
          }
        },
        "40b705d35f564a2fb6a0efa0224a18ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccab2b5d14584824bf3201412cf2aff7",
            "placeholder": "​",
            "style": "IPY_MODEL_b626ce2f60fd4d668e1e8acb3740e2a1",
            "value": " 416M/416M [00:07&lt;00:00, 57.6MB/s]"
          }
        },
        "d376626d7f0e45138d78d2fa01b0b96f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3175ca09414480b1f1c48f48c781f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b8649914fe41adad872b50abaf6ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87b47d5d4de4e1e8a62c2925b5579b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce9bee1bcf8415eab95865aa153dbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccab2b5d14584824bf3201412cf2aff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b626ce2f60fd4d668e1e8acb3740e2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujin-create/hodlhodl/blob/Sentiment-analysis/Reddit%20sentiment%20analysis%20with%20Transfer%20Learning%20BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9ox05GPpbsx",
        "outputId": "12fe416a-38af-48e8-942b-d53d595e0740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment analysis with BERT\n",
        "Reddit Bitcoin 카테고리의 daily discussion 댓글을 날짜 별로 크롤링하여 감정 분류를 진행한다.\n",
        "* Comments crawling: Using praw API\n",
        "* Sentiment analysis: BERT model을 전이학습한 후 크롤링한 댓글을 Test하여 감정 분류 결과를 도출함. Negative는 -1, Netural은 0, Positive는 1의 가중치를 부여하여 K 가중치 값을 계산함. K 가중치 값은 비트 코인 주가 예측에 활용할 예정.\n",
        "\n",
        "> 아래 코드를 직접 실행시키는 경우 시간 관계상 훈련된 모델을 다운받아 테스트를 진행해도 됨\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkRrv6AYEhZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crawling comments of Reddit 'Bitcoin' Category Daily Discussion "
      ],
      "metadata": {
        "id": "EnfC6eqzF6Vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzMNBSxkEOMg",
        "outputId": "795cd469-953f-4248-d6c3-2009ff8d9697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.5.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.54.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting prawcore<3,>=2.1\n",
            "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting update-checker>=0.18\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from prawcore<3,>=2.1->praw) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
            "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
            "Successfully installed praw-7.5.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install praw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"zqpaU6K2Gb1O4OMDyzPbKg\",\n",
        "    client_secret=\"u43AeHP8QG-wzw4SzUWIfcJi7iLRkg\",\n",
        "    user_agent=\"ysoorim\",\n",
        "    username=\"ysoorim\",\n",
        "    password=\"cindy102503!\"\n",
        ")"
      ],
      "metadata": {
        "id": "J5JLMr20GJWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subreddit = reddit.subreddit('bitcoin')   # subreddit: 토픽, submission: 게시글, comment: 댓글\n",
        "submissionID = []   # Daily Discussion의 게시글 ID를 저장\n",
        "\n",
        "for submission in subreddit.hot(limit=1):   # Daily discussion 2개가 (어제, 오늘) 동시에 있는 경우 확인하기\n",
        "  submissionID.append(submission.id)\n",
        "  print('submission title: ', submission.title, '\\nSubmission ID =', submission.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBy0SXx-GMNI",
        "outputId": "7bee63c2-0336-4403-f0a9-4838b1957a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission title:  Daily Discussion, May 10, 2022 \n",
            "Submission ID = umawha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Daily discussion ID를 활용해 게시글에 대한 정보 출력\n",
        "comments_all = []   # 전체 댓글을 저장\n",
        "dailydiscussion = reddit.submission(id = submissionID[0])\n",
        "dailydiscussion.comments.replace_more(limit = None)\n",
        "\n",
        "for comments in dailydiscussion.comments.list():\n",
        "    comments_all.append(comments.body)\n",
        "print('총 댓글 개수: ', len(comments_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBV4zeKnHBV5",
        "outputId": "33d9d372-a89a-4acb-b16f-085878c8dcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 댓글 개수:  232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comments_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n4pyGynHxIB",
        "outputId": "777a1990-041d-4764-de40-fef89df69d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bought a certain shitcoin a month ago that’s now tanked 80%. Flipped what was left of it into Bitcoin. Lesson learned. No more shitcoins',\n",
              " 'The cnbc article on how 40% of Bitcoin investors are underwater is on the front page and overflowing with cringe. Bet cnbc won’t do an article about how anyone who started investing in the stock market in the past year is also likely deep “underwater.” Netflix, Amazon, Facebook, twitter, google…all red YoY. Not to mention the smaller tech sector.',\n",
              " 'If you woke up holding BTC…..you winning 🏆',\n",
              " '*\"Round 2, fight!\"*',\n",
              " 'Just stacked some more cheap sats. Life is good.',\n",
              " 'someone sold me bitcoin at 30,000. tysm',\n",
              " \"Seeing all the people accumulating and hitting new sat stackin milestones makes me so happy. I'm proud of everyone who is reaching their goals and working toward bettering their future during these times.\",\n",
              " 'Good job hodlers.\\n\\nYour accumulative resistance in the past few hours have proven once again how powerful the Bitcoin community and ecosystem are, as well as how much willing they are to throw their last penny into dips such as these.\\n\\nExtra kudos for those that took their coins out of the exchanges.',\n",
              " 'Haha when you want to listen to the saylor series and you keep typing the taylor series and blame youtube for not finding what you want',\n",
              " 'Personally I’m gonna keep buying, imagine being such a gimp you gotta sell off your coin',\n",
              " 'r/cryptocurrency is insufferable right now',\n",
              " \"I thought I was about to witness a black hole forming in real-time as UST goes to $0.6. it made me drink coffee without water so I won't  be able to blink while watching as it sucks the value out of my UST away to the void\",\n",
              " \"I'm a Bitcoin Maximalist and perma-bull. I still HODL 10+ BTC. That said, we will likely go much lower before we get new ATHs. Historically, we've bounced off the 200-week moving average during bear markets. We're in a bear market right now and the 200-week moving average is around $21,000. Hold on to your butts. That would bring us right around a 71% drop from the ATH, which is close to what has happened in the past. Just don't be surprised if it happens and be ready to buy a shit ton of BTC if hits below $25k.\",\n",
              " 'Life is good',\n",
              " 'How long do people think we have until what’s happening in Sri Lanka comes to the “First World”?',\n",
              " 'I’ve been DCA’ing into BTC and Alts for a few years always intending to realize bigger Alt gains and convert to BTC for the long term Hodl. At this point my BTC investment is still up and I never sold any Alts at the top to convert. My Alt bags are negative. I’m going to hold long term but it really has me thinking my DCA should be majority to 100% BTC going forward.',\n",
              " 'I meant to buy more on the dip but I got busy at work and now idk if it’s dippy enough for more.',\n",
              " 'Great Discounts 🤩\\nIs there anyone here today who is not a Satoshi millionaire?',\n",
              " 'Strike won\\'t let me buy. \"unexpected server error”. Anyone else have this?',\n",
              " 'Did we find the bottom??  I personally think we’re going a bit lower but not by much.  28k',\n",
              " 'Hang on to your mother fucking ‘Toshis!',\n",
              " 'Where can I find more complete/recent info on bear markets than the article below?  I’m curious how long the average bear market lasts to maximize my DCA strategy over the next few months.  [BTC Bear Markets](https://medium.com/mosaic-network-blog/a-brief-history-of-bitcoin-bear-markets-1eeac2d646e5)',\n",
              " 'If you look at the March 2020 crash on the weekly RSI, you can see we are very close to the same level. Let’s just say, I wouldn’t be opening up any shorts right now, as we are highly oversold.',\n",
              " '100k by Q7 2021!',\n",
              " 'Dont you know? Pump it up!',\n",
              " \"How long till the 19 year old bear comes out and explains how us oldsters lost everything and all the other little bears agree and those of us who know better don't call them out on this. Hey here's one for you. You don't lose till you sell or never sell at a loss. Maybe 75% of the one's on this sub are 19 year old bears IDK. They always say I've been following BITCOIN since it's inception but don't own any but...\",\n",
              " 'Town Square Media buys £5mil of BTC. \\nNice entry price.',\n",
              " 'Binance has 8%!! more deposits in wallets as 24h ago. That is massive. Never seen such an increase.\\n\\nhttps://glasschain.org/',\n",
              " \"C'mon, surely someone else knows what it's gonna do\",\n",
              " 'Does anyone here think that Financial institutions have entry points / plan to make entry points here or somewhere slightly lower? \"Bull markets will make you money. Bear markets will make you rich.\"',\n",
              " 'Buy now or forever hold your peace!',\n",
              " 'Still HODLing \\n\\nI hope Do Kwon shuts his show down, and either Hodls or donates the LFG BTC holdings',\n",
              " 'Okay guys hear me out, I have a logical theory. So Bitcoin starts with a B. The symbol for it also resembles the letter B.\\nI personally never pull out ; ) and Plan B has always worked for me.\\n\\nHodl!\\n\\nIn all seriousness PLEASE get your coins off of exchanges. I can’t stress this enough.',\n",
              " 'Seat your belt guys.',\n",
              " 'Same market behavior today, zigzagging like a drunken sailor. I was hoping we would get a straight up bounce today but someone must have soiled the sheets.',\n",
              " \"El Salvador bought 500 BTC 20 hours ago. Since then, 750 BTC has been mined. We're still early.\",\n",
              " '1 btc = 1 btc',\n",
              " 'Europe is awake to rescue this',\n",
              " 'Next mega dip ready to drill',\n",
              " \"....aaaannnnnnd we're back\",\n",
              " 'Stocks will rally tomorrow',\n",
              " 'Time for community driven short squeeze? Did my buy yesterday at those levels and of course took those btc to cold storage where they will wait until daily RSI hits some crazy over bought levels again :) \\n\\nNot your keys not your btc!',\n",
              " 'The bears are back to spam the board. Great time to buy.',\n",
              " '40k by next week',\n",
              " 'Citizens of Bitcoin, we have survived the dip! Hold fast, all!',\n",
              " 'SHES ALIVE',\n",
              " 'If you think this price action is rough, try holding Bitcoin mining stocks... Oof.',\n",
              " \"I honestly don't know what today will hold. We may crash some more, we may pump, we may crab.\",\n",
              " 'I’m down a lot like so many people. No Pain, No Gain!',\n",
              " 'Lol',\n",
              " 'Ok, Ciao.',\n",
              " 'Dead cat bounce?',\n",
              " 'Dead kitty trap',\n",
              " \"Well, it tickled below $30k for a few moments, but a cautious recovery since. Maybe that's the support level for a while? Could be worse.\",\n",
              " \"if any moonboys here have any delusions that bitcoin isn't going to 20k, you're wrong.\\n\\nit will go to 100k+, but first your suffering must be greater.\",\n",
              " '☕️',\n",
              " '☕️🍩',\n",
              " 'Pain over?',\n",
              " \"I have a serious question regarding Bitcoin and Cryptocurrency. Someone please clear my doubt.\\n\\nThe main advantages of Bitcoin or any solid crypto currency are 1) accessibility across borders 2) Transparency and anonymity 3) Govt. can't control it's value. Because of all these and other benefits, we claim that people should migrate from govt controlled currency to Bitcoin and crypto. \\n\\nA lot of people claim that govt. not having any power on the currency as the best thing but the following logic says otherwise.\\n\\nToday Bitcoin is technically superior than any fiat currency. Say, if almost all of us migrated to Bitcoin and made it the primary currency in a few years. And later a new digital currency, based on a technology much better than block chain, is invented by someone and it has all the above said benefits of Bitcoin and also has less limitations (Example: less energy consumption, faster transactions, less data to be maintained etc). Following our logic, we should all migrate to that new coin making bitcoin invalid if govt has no control over their country's currency. With time, technology develops exponentially and new, better currencies will come more frequently making the previous one useless. So all the currency you earned based on your hardwork, jobs etc becomes less valuable because a better currency is in market and you don't have it yet.\\n\\nYou see the problem in the above scenario right? We can't have an independent currency like that if we want stability in the society. Shouldn't we have govt. control over it. After all, Govt is the representation of their citizens. They are the people and work for the people only. Atleast in theory. \\n\\nCan someone please explain if my thinking is wrong and why is govt control bad?\",\n",
              " '32 THOUSAND AMERICAN FREAKING DOLLARS! 🥂',\n",
              " '$1,000,000,000 USDT (1 Billion) printed at Tether Treasury...\\n\\nPreparing to buy after the bear run?\\nOr going to jump in and start buying now?',\n",
              " 'Another 10% about to get wiped off.',\n",
              " 'Is this the right time to buy btc or should I wait until Friday the 13th?',\n",
              " '[removed]',\n",
              " 'Caught the bottom and everything in between 😂',\n",
              " \"So I've been on Twitter because shit's actually been interesting lately. There are tons of dudes talking about Bitcoin and economics stuff of course. There are a few women here and there, but I've noticed every woman I see posting is super attractive. Why is that? Are there no ugly women in crypto?\",\n",
              " \"I don't think I'll be satisfied with the dump until we hit ~$20k.\\n\\nOnly then will I be happy about the pump.\\n\\nThat or when we somehow hit over $200k\",\n",
              " '[deleted]',\n",
              " 'new-ish to crypto. Will btc go back up a little bit in the next few days meaning i should buy right now with instant bank deposits on [crypto.com](https://crypto.com) or do i have time to wait for ach transfer?',\n",
              " '☕️🍳🥓🍞🔫🦅',\n",
              " \"There were several posts around that called this the death of alts.  It isn't but it's a good start.\",\n",
              " 'Hi team, wanna put another 20k down on da BTC. How low is this low gonna go? 🤔  ... buy now or wait it out a little?',\n",
              " 'I have a decent bag (like, more than $50 😅) of one alt that I thought sounded nifty and it’s down like 70% too even after I DCA’d a bit during the run down. I think it’ll be one to still be there whenever this bear ends in a couple of months/years so it’s just sitting on an exchange gathering interest. If it never recovers, well, I’ll go down with that gamble. It was a learning experience if nothing else. \\n\\nDuring my last big drop last summer I was only on btc do I didn’t have the first hand experience of how much alts get destroyed. It certainly hurts less having 90% your portfolio on Bitcoin at times like these.',\n",
              " \"Now you've put your money in a safe investment how has it performed in the month since you did it?\",\n",
              " 'Every alt that i hold is still up compared to btc tbh. Started febr last year... Just saying. Started converting them all into bitcoin tho.',\n",
              " 'Just noise. Shows once again how early we are. Every upvote is another crab trying to pull us back into the pot to cook with them.  People hate seeing others believe in something, put their money where their mouth is, then succeed.  \\n\\nThey’d much rather believe they were right all along, btc is some scam that they don’t understand, etc.  If you’ve been here over 2-3yrs this all looks familiar.\\n\\nDon’t invest what you can’t lose, but keep believing. There is a better way, a better money, and damn if you haven’t found it before most of them.',\n",
              " 'Doing that everyday and everytime though just let things go accordingly.',\n",
              " '**Hadouken!**',\n",
              " 'Spinning bird kick!',\n",
              " 'Thanks, Altruistic_Banker',\n",
              " \"Why, I laugh at that casino all the time.\\n\\nMost of the crypto tards are concentrated there. It's funny when you don't take it seriously.\",\n",
              " 'Welcome to my world!',\n",
              " 'I can\\'t even read posts on there. Everything goes to \"daily discussion\" thread loool',\n",
              " 'When is it not lol',\n",
              " '> drink coffee without water\\n\\nExplain',\n",
              " 'I might be able to finish stacking my first whole coin at that price... 👍',\n",
              " 'I still believe a spot ETF will surprisingly happen in july followed a major price appreciation and  keeping us way above the 200 wma. But hey i am just a guy from the internet',\n",
              " 'Got a buy order at $23,500',\n",
              " \"I don't care for charts and all that but wouldn't an exponential moving average be more meaningful than a simple moving average if you're talking about weekly prices over long periods for Bitcoin considering if you zoom out enough to even chart those lines you're looking at a big exponential move?\\n\\nNot really relevant to your point. Just asking.\",\n",
              " \"I normally agree but 69k was such a diminished return this cycle that one would think we wouldn't have to drop all the way to the 200 week. But I do agree we will go lower. Lower than 28k? I dont know but anyone rejoicing today over a 31k btc during a bear market doesn't have their reality in check.\",\n",
              " \"We could bounce off of 200 week in a few months when it's much higher than today.\",\n",
              " 'Limits 25k, limiting the fuck outta 22k, and selling everything I have if we hit 18k to buy more',\n",
              " 'What kind of timeframe for that to happen?  I know Bitcoin does what it wants but do you think we’ll see a slow bleed the rest of the year?',\n",
              " 'Looking for more bear market info… lengths, % dip etc. Can you point me at some source material please?',\n",
              " 'you mean when the shithole trades the gucci belt for crack?',\n",
              " '50 years or so :)).',\n",
              " \"Most 'toxic bitcoin maxis' have had similar realizations. Shitcoins trend to zero against Bitcoin.\",\n",
              " 'Old ATH -50% is not enough? Any price today is enough to become wealthy by holding it 10-20 years while accumulating more.',\n",
              " 'I haven’t had any issues.',\n",
              " 'do not buy now its going down',\n",
              " 'With Bitcoin, you don\\'t need to \"maximize\".  You just need to buy Bitcoin, send it to your own (hardware) wallet, and hold, long term.\\n\\nKey: long term.',\n",
              " \"The whole point of DCA is that you don't need to think about it.  Just buy what you can every day/week/month, whatever time interval works for you, and don't look at the price.\",\n",
              " 'Also stochastic has only been this low thrice in the history of btc.',\n",
              " 'I love how he continues to tweet his bs charts like nothing happened. The man is a living example that nobody knows shit about future price.',\n",
              " \"Lose* - Loose means 'not tight'\",\n",
              " 'Honest question from a newbie, who is this 19 years old bear you are refering to?',\n",
              " 'The next 10 years is what I see something positive enough in the graph would come out.',\n",
              " 'crypto whale troll says they did two months ago',\n",
              " 'Let time just go and we would surely know what the right thing actually is.\\n\\nJust give that time have some patience and just make that flow in the right direction.',\n",
              " 'I do. It will move to the right. 100% certain.',\n",
              " 'I think institutions have their entry point at $38,000.  \\n\"Bulls make money, Bears make money, pigs get slaughtered.\" \\n\\nhttps://www.cnbc.com/2022/02/09/jpmorgan-pegs-bitcoins-value-at-38000-says-nfts-are-set-to-dominate-digital-assets.html',\n",
              " 'Or don’t buy and continue to hold your piece',\n",
              " \"i'm a buyer at 10k.\",\n",
              " \"major stock indexes in free fall, they'll probably halt trading if it gets much worse because if they don't like whats happening they just shut it off. Cant do that to btc!\",\n",
              " 'Affirmative',\n",
              " 'You’ve been spamming bearish shit no matter the price.',\n",
              " 'Bahhaa',\n",
              " \"We're still in a bear market, though. Rejoice nonetheless. We have the great privilege of stacking now before the scores of future Bitcoiners are even born. There will only ever be 21 million.\",\n",
              " 'The dip? It’s just started.',\n",
              " 'Nope',\n",
              " \"I dabble in the miners. I can verify the foregoing. Dudes are getting wrecked. But they're severely undervalued now. It's better to hold Bitcoin, but having a little bit in these miners might be a good play.\",\n",
              " 'I wonder who buys that crap.',\n",
              " 'Mhm.',\n",
              " \"We likely crab until cpi numbers are released at this point. Can't see us going below 30k or above 32/33k\",\n",
              " 'Looks like some stocks are up in pre-market. Given that Bitcoin looks to be correlated, my humble view is that it should be a better day',\n",
              " 'Yep. Those are the three options.',\n",
              " 'Looks like the market is all on fall we ought to look for some good days ahead!',\n",
              " \"Good point.  I'm going to guess no *wince* and wait.\",\n",
              " 'Kitty licked rat poison first',\n",
              " \"Eventually, one Bitcoin will buy more than one million of today's USD buys.  If it goes to $20K first, BFD.\",\n",
              " 'Psshh, I held through 2018-2019.  This is nothing.',\n",
              " '⚡️',\n",
              " 'The beatings will continue until morale improves.',\n",
              " 'No',\n",
              " 'The next Bitcoin is Bitcoin.',\n",
              " \"You're forgetting the network effect. A currency is only valuable if lots of people are using it. Right now, the dollar has massive network effect and it is very difficult to get people to change from it (or add something else to what they use). If another currency is able to cause a change, it will be because it is much superior, not slightly superior. That's the position Bitcoin is in right now. By many people's estimation, it is much superior and it already has the network effect in the crypto world. Would someone then want to switch from BTC to something else? Maybe but it would need to be much superior to BTC to overcome the network effect. And many changes or improvements that we can imagine could just be integrated into BTC as it is upgradeable technology rendering a complete change unnecessary and unlikely.\",\n",
              " 'The only constant in life is change. If theres anything better than bitcoin then people can migrate to it. The advantage of crypto is not stability in society, that stability can only be achieved by good government policies, which is dependent on who is in the government.',\n",
              " 'Government control of currency value or ability to issue or manipulate value is inherently disastrous. Let me illustrate. \\n\\nFor centuries, gold was the ultimate store of value and medium of exchange. It was anonymous, had zero counter-party risk, and was resistant to manipulation. It didn’t make one ass hair of difference what clown’s face was stamped on it. Country of issuance didn’t mean shit. Gold was gold was gold no matter where it came from. It was the ultimate decentralized money. The world got along just fine. \\n\\nNow let’s talk about what happens when the government in their ultimate wisdom puts their fucktarderized hands on money. A clear early example was the Roman denarius. It started out as a mostly silver coin. Government manipulation slowly lowered the silver content until after a few hundred years the silver was effectively removed. The coins were no longer valued at home, but more importantly abroad. \\n\\nHere in the US, the paper dollar was nothing more than a debt instrument. An IOU or coupon redeemable for whatever amount of gold was printed on it. $20 bill could be brought to the bank and traded for a $20 gold piece.   \\n\\nDecoupling gold from the dollar, which happened in increments over several major events during the twentieth century- creation of the fed, gold confiscation and revaluation by FDR, Bretton-Woods, and Nixon’s decoupling. ( Look them up and read at your convenience), essentially destroyed the value of the dollar, which continues to this day and is what the creators of the problem, the fed, are desperately trying to get under control- the effects of which you read about daily in the paper. \\n\\nLet’s illustrate further. Remember that fat $20 gold piece we talked about earlier? Well you’ll be relieved to know that you can still buy gold for $20. Of course you’re going to need tweezers to pick it up and make sure there isn’t a strong wind present or you might lose it. Oh, if you decided you want that $20 gold piece instead, you’ll need to fork over $2000. Yes, you read that right. \\n\\nThat’s why government money is a bad idea. Just think of bitcoin as modern gold. Except it’s confiscation-proof if handled properly and can be transported safely from anywhere to anywhere. \\n\\nAs a side note, I recently read about some poor guy from India who got caught trying to “smuggle” HIS OWN GOLD into of the country. Here’s how desperate he was to move it anonymously. He melted it into a dildo and had it stuffed up his ass. He lost the gold, his freedom, and his dignity. Why? Because of a country’s psychopathic need to control other people’s money. Bitcoin more than fixes this, and btw, it’s easier on your ass during international travel\\n\\nIf anything changes and something comes along better than bitcoin ( I don’t think that’s gonna happen but who knows) then people should also be free to migrate to the next great thing. Government is inherently corrupt. It’s only to what matter of degree that’s ever in question.',\n",
              " \">why is govt control bad? \\n\\nAsk the protesters at Tiananmen Square. Oh wait, you can't.\",\n",
              " \"> We can't have an independent currency like that if we want stability in the society.\\n\\nMoney is a technology, as you mention in your post. From time to time, one money is going to supplant another, because it's better. \\n\\nYou're not going to have a new Bitcoin every 10 years. The emergence of Bitcoin in a fiat world is like the emergence of gold in a seashell-based world. It was the basis of wealth for thousands of years.\",\n",
              " 'Govt don’t give a sh1t about you. A govt backed coin is just fiat.',\n",
              " '[deleted]',\n",
              " 'Wait till next all-time high, then buy.',\n",
              " 'Shitcoins and other such irrelevant scams are off topic here.',\n",
              " 'Lmao you just seem to be a good catcher and the fact that you must be fond of playing cricket.',\n",
              " 'Yes exactly.',\n",
              " 'Can you link some of these women? It might just be a planned career, where they want to establish an influencer persona, and some may have found in crypto its not a bad niche.',\n",
              " \"Why are you here? You clearly don't give a shit about Bitcoin. Or rather, you seem to desperately want it to fail? Why? You obviously have no skin in the game. So you're just here to spread negativity and FUD for something that you personally stand to gain nothing by, whether it goes up or down. You don't have a better way to spend your time?\",\n",
              " '[removed]',\n",
              " 'People do not have the ability to predict the future. Whether it\\'s \"crypto\" or otherwise.',\n",
              " 'You should not buy Bitcoin for the hopes of it going up in the next days. No one knows what happens in short term but more and more people, companies and whole countrys know how high it will go in long term. You can become very wealthy in 10-20 years with Bitcoin. But not in 10-20 days.\\n\\n\\nStack sats, take it off the exchange account and learn more about Bitcoin.',\n",
              " \"I'd do both.  I have done both, repeatedly recently.\",\n",
              " 'Old-ish to bitcoin. Yes it might go up a little so you should consider to buy now and also think about waiting on your transfer.',\n",
              " \"Can't tell the future, but I'd say the chances of a significant jump in the next few days is unlikely. Probably safe to wait\",\n",
              " \"The Bitcoin CEO knows what the price is going to do, but he's never going to tell us.\",\n",
              " 'Split it up into 4 chunks and invest 5k each week.  Yay averaging.',\n",
              " 'Just invest periodically like if it was a pension fund, come back in 10 years. Maybe retire. Maybe not.',\n",
              " 'High time to buy though just go for it homie buy as much as you want.',\n",
              " 'If it cost you 50 dollars, that is a cheap lesson. There are people losing thousands or tens of thousands in their shitcoin casino.',\n",
              " 'Nah I flipped the shitcoin into BTC only today. However I’ve done well out of BTC because of my entry point',\n",
              " \"That is the ultimate trust we got Bitcoin is what we believe and we know what it is and what the outcomes are.\\n\\nWe know this all ain't a scam and the game is indeed all about long term the one who knows :)\",\n",
              " 'Hundred hand slap -E. Honda',\n",
              " 'My pleasure 😄🙏\\n\\nMay the hodling force be with you.',\n",
              " 'That is when you eat coffee beans, grind them up with your teeth and swallow.',\n",
              " \"There is no way Daddy Gensler will allow this. They have been quite clear, i don't know why you think they would reverse.\",\n",
              " \"I'm not sure. I couldn't easily find an EMA for Bitcoin.\",\n",
              " 'I suppose it could hit 25k in several months.',\n",
              " \"Probably.  On the other hand, the lower the price is in the near term, the longer it'll take for the average to move up appreciably.\",\n",
              " \"Check out lookintobitcoin.com/charts and see if you can spot any historical trends. There's no guarantee, especially since we are seeing some big moves with inflation and economic uncertainty like we've never had before since Bitcoin was created. \\n\\nHere's one thing I'm relatively sure of: Bitcoin will look pretty good in 2025-2028 compared to now. Now's not a terrible time to be buying Bitcoin if you're looking at a long term timeline.\",\n",
              " 'Lookintobitcoin.com/charts',\n",
              " '🎵 The toxicity of our city, our citadel 🎵',\n",
              " 'I’ll buy more today too',\n",
              " \"Thanks. It's working now!\",\n",
              " 'Probably but I always buy. Stacking for the future.',\n",
              " \"Terrible advice. If no one is buying then the price isn't going back up.\",\n",
              " 'I dread to think how many people leveraged up in anticipation of the golden bullrun and were subsequently wiped out. :(',\n",
              " 'Well ain’t you’re the grammer police over their.',\n",
              " 'People who recently got into crypto (less than 6 months ago) who are now panicking about all the money they are currently losing because they bought at $45-47k.\\n\\nPut it on sale.',\n",
              " 'Wont see it',\n",
              " 'Yup. Talking to my friend in Asia and the East is beginning to jump on the Bitcoin train. Lots of investors there because of high birthrate. Don’t trust the western media, especially with people like Liz Warren around.',\n",
              " 'Those who bought the bottom making money again. You must have missed it',\n",
              " \"Those who don't want to sell their crypto, but want to 50x their fiat, pretty simple really. Good plan to be doing both.  \\nThere was a higher rate of return this last cycle with mining stocks than BTC. Those that got a high ROI, can now use that to buy some cheap sats. It's a smart play, use it to your advantage.\",\n",
              " 'If stocks are green btc will be too. It is EXACTLY correlated',\n",
              " 'Ahh 40 hrs a week.',\n",
              " 'Sure?',\n",
              " \"I would like that too. But it isn't logical enough for my brain to convince itself. Haha\",\n",
              " 'Some good points here',\n",
              " \"So you also agree that if there's anything better than Bitcoin, people can migrate to it. \\nMost of the society is not into financial markets. All they want is to get paid for their work which they can use to buy stuff. If bitcoin is the common currency instead of a govt backed one, the day the better currency comes, a nurse or a carpenter who got paid in bitcoin will have no longer have the money, they think they had, for buying their car. Because bitcoin has lost value with the new currency.\\n\\nThis day will come some decades or centuries later. But since technology develops rapidly, newer better currencies will come more regularly and your saved money of that year will lose value more frequently.\\n\\nYou see, my doubt is not merely about bitcoin. But it seems govt (which is the people) agreed and approved currency is central to society.\",\n",
              " 'I love this explanation. Especially the \"easy on your ass\" part.\\n\\nBut can I ask a follow up question. You said i need 2000$ for the previous 20$ worth of gold right. This happened over some decades.\\n\\nIf we only had gold and no paper currency and initially i would be able to buy a bike for that gold piece. But after all those decades, i wouldn\\'t even get the tires of that bike with the same weight of gold right. Because of inflation. Doesn\\'t matter if I am using gold currency or paper currency. What ever is the sole currency will lose it\\'s value over time right? \\n\\nTell me if I\\'m wrong',\n",
              " \"\\nHow can we claim that we're not going to have a new bitcoin. After all, crypto currencies are technology based. And as we know, technologies develop rapidly sometimes. Block chain can't be the pinnacle. There might come a better technology right? \\n\\nMoney or currency evolved like bitcoin. Group of people agreed to use the same thing for exchange of goods. More and more people joined and finally govts settled. So to have a stable currency we want all people to accept it. Without technology by my above logic, people will leave old currency for better ones. Govt. With laws brings stability to a currency.\",\n",
              " \"But govt is us people right? An individual policy maker doesn't give a shit about me and I agree. But government is representation of people, which ever party might be ruling. When govt constructs a bridge or road, it is us people constructing it for ourselves. \\n\\nI know it's all ideal scenario but all I'm talking is in theory. Currency has value only if the citizens of that nation agree that it's the common currency. We people through govt have established that dollar is currency for US, Pound for UK and Rupee for India.\\n\\nIf we ignore this concept of currency and select a currency based only on benefits, any currency will go down when a superior technology based currency comes into place. We the people of the world should have a common consensus that this is our currency and when this consensus comes to any currency it becomes the govt currency naturally\",\n",
              " \"If bitcoin becomes official currency, govts will take debts in bitcoin. That has nothing to do with what kind of currency they're using but inefficient policies.\\n\\nAlso when I think of Bitcoin future, i see it growing to be a global currency. Which means it'll grow a hundred times than it is now. Because clearly bitcoin has many advantages than the traditional one. But why do people compare a currency with a company. bitcoin is the currency in which you have to measure a company's value. Not compare\",\n",
              " 'just want to protect my BTC investment, but ok',\n",
              " \"The only time I spend is shorting Bitcoin I work for a Fortune 500 company. I've made millions off shorting Bitcoin. So whenever you guys dump it guess what Daddy gets all the money. I love people like you keep pumping it up so daddy can dumpy dumpy.\",\n",
              " 'I love you',\n",
              " 'I’m generally risk averse and even getting into Bitcoin was a huge transformative moment for me. I couldn’t stomach putting serious money into anything else. RIP everyone who’s not in a good place right now.',\n",
              " 'Whoooopsieeeee!',\n",
              " 'To avoid lawsuits by greyscale and to final understand what free market participates wants after years of criticism from even high level politicians? \\n\\nThe pressure is growing from multiple sides. They’ll wave the white flag soon or later.',\n",
              " 'Yeah I’m in it for the long haul, I look at it as another form of retirement.  I’ve been buying weekly for only a year now but haven’t sold any and have no plans to.  Hopefully be a multi coiner like yourself one day.',\n",
              " 'if u going to buy with big amounts just wait thats what i wanna say',\n",
              " 'judging by the comments on his recent tweets, not enough. TA is bullshit, fellow kids, the only question is how much money do you need to burn to learn that lesson.',\n",
              " 'Misspelling lose as loose distracts from the message and undermines his competency.',\n",
              " 'Oh i get It. Thanks!!',\n",
              " '[deleted]',\n",
              " 'K will buy some shitty RIOT at 2 dolls if you insist.',\n",
              " \"The cantillionaires don't get it yet\",\n",
              " 'Incorrect, If I’m understanding you properly. The $20 gold piece would buy you ten cheap bikes or one nice bike now. The gold has retained its value. Inflation isn’t a necessary given. It’s an effect of printing money. Even printed money could work as a way to store value. The trick is getting the approved creators to stop printing it. You and I both know that will never happen',\n",
              " \"If a better currency than bitcoin is developed, we will migrate to it slowly.  Bitcoin didn't get adopted overnight, and neither would this hypothetical better currency.  No need for government intervention.\",\n",
              " \"If there could have been a new Bitcoin, there would have been Thousands of alternatives, a decade gone by, still nothing. Says something.\\n\\nAnd hey, if after Bitcoin there's something even better, bring it. And I'm getting Bitcoin now so I can buy more of whatever's best at that point.\",\n",
              " \"Yes. There are better technologies coming all the time, and the best of those are adapted to bitcoin.  \\nWe have the lightning network now. Which clears away some of blockchain's limitations.  Bitcoin keeps being patched constantly. And if you want, you can make a bitcoin that is Proof of Stake, very easily.   \\nIt's just that nobody wants it because of the drawbacks (I don't want you to just believe me on this, because it's very contested, but there are drawbacks and it's a good idea to read about why PoS might be inferior to PoW).\",\n",
              " 'So no need to talk about shitcoins then.',\n",
              " 'Works for fortune 500 making millions shorting corn / Posts memes on wsb reddit all day. Pick one.',\n",
              " 'So you make fortune cookies? Cool!',\n",
              " 'Cool story, bro. I totally believe you. 🤡',\n",
              " \"Hilarious cosplay, don't you have anything better do to with your time?\",\n",
              " \"You're funny\",\n",
              " 'I think they were warned market is cyclical often enough, don\\'t feel bad for them.\\n\\nMany even took a loan or spent money they needed not to spend.\\n\\nMarket will eat them all.\\n\\n&#x200B;\\n\\nThe last thing many will do to seal their fate is to \"sell now to cut their losses\".',\n",
              " 'Oh I know, my reply was just meant as sarcasm haha.',\n",
              " \"My message fell on deaf ears anyway or maybe a 19 year old college educated bear. Either way I'm a trucker been home for 3 months because freight rates are half what they were, fuel twice what it was, but I'm not selling. Digest that sir.\",\n",
              " 'If you hang around corporate circles enough, you can usually see that incompetence makes you more money lol.',\n",
              " \"I agree with you. But another part of doubt is that in future because of exponentially growing technology, newer better currency would be coming by the time we migrate to the first new currency. Doesn't that make it very unstable.\\n\\nOr is my logic too hyperbolic. Like apocalypse or AI overtaking the world?\",\n",
              " \"It took thousands of years for dollar to emerge from the copper coin currencies. It took hundred of years for bitcoin after dollar. Similarly it'll take decades at the least, for a better one to come.\",\n",
              " 'Thank you. I am unaware that new technologies are being implemented into bitcoin to make it better.',\n",
              " \"I'm gay but do I love cock.... No.\",\n",
              " 'I also make penis cookies',\n",
              " 'Your mother believe me last night',\n",
              " 'Anal. I like anal',\n",
              " \"Are you calling me gay? That's not very 2022 like\",\n",
              " 'Tech moves fast but people do not.',\n",
              " \"Bitcoin is not static, it's a hotbed of technological development. Anyone saying bitcoin is 'old tech' is likely shilling a shitcoin.\",\n",
              " \"I bet you're fun at parties. Back to buttcoin with you, sad little troll.\",\n",
              " 'Show me your gains bro. I need gains porn']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe으로 변환 후 날짜, 댓글, 분석 결과(분석하면)를 csv 파일로 저장함\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "date = datetime.today().strftime('%Y-%m-%d')  # 날짜 출력\n",
        "results = []  # 감정 분석 후 결과 저장\n",
        "\n",
        "data = {\n",
        "    'date':date,\n",
        "    'comments': comments_all,\n",
        "}\n",
        "\n",
        "df_comments = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "-2kLnnwfI158"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fATRUn3pJvUy",
        "outputId": "07315835-96dc-4ef9-ed4c-97139fe8b84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           date                                           comments\n",
              "0    2022-05-10  Bought a certain shitcoin a month ago that’s n...\n",
              "1    2022-05-10  The cnbc article on how 40% of Bitcoin investo...\n",
              "2    2022-05-10         If you woke up holding BTC…..you winning 🏆\n",
              "3    2022-05-10                                *\"Round 2, fight!\"*\n",
              "4    2022-05-10   Just stacked some more cheap sats. Life is good.\n",
              "..          ...                                                ...\n",
              "227  2022-05-10  Are you calling me gay? That's not very 2022 like\n",
              "228  2022-05-10                 Tech moves fast but people do not.\n",
              "229  2022-05-10  Bitcoin is not static, it's a hotbed of techno...\n",
              "230  2022-05-10  I bet you're fun at parties. Back to buttcoin ...\n",
              "231  2022-05-10          Show me your gains bro. I need gains porn\n",
              "\n",
              "[232 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3168ddf-1948-4ecf-a472-6411648cf56b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Bought a certain shitcoin a month ago that’s n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>The cnbc article on how 40% of Bitcoin investo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>If you woke up holding BTC…..you winning 🏆</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>*\"Round 2, fight!\"*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Just stacked some more cheap sats. Life is good.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Are you calling me gay? That's not very 2022 like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Tech moves fast but people do not.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Bitcoin is not static, it's a hotbed of techno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>I bet you're fun at parties. Back to buttcoin ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Show me your gains bro. I need gains porn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3168ddf-1948-4ecf-a472-6411648cf56b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3168ddf-1948-4ecf-a472-6411648cf56b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3168ddf-1948-4ecf-a472-6411648cf56b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT 모델 학습 및 테스트를 통한 감정 분석"
      ],
      "metadata": {
        "id": "q2qptxR4K2nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi   # GPU 상태 모니터링"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULElGwVlK9Jk",
        "outputId": "7e983092-4572-4c01-c024-78373e1f1f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 10 15:46:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 라이브러리 설치"
      ],
      "metadata": {
        "id": "Z2nV1zwnLbdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U watermark\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnaeLnWZLZGO",
        "outputId": "c0590494-f24e-4dd1-8016-5b069554b51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 2.1.3 which is incompatible.\u001b[0m\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (2.1.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=00c772db026346f4aacd3012de4f7b3442f264c97bb17d0274934a993ac88e9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF667bE8LjqA",
        "outputId": "08ffe04d-d626-4957-9c9f-d50539ec892d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.13\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.21.6\n",
            "pandas      : 1.3.5\n",
            "torch       : 1.11.0+cu113\n",
            "transformers: 4.18.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0K-iv7rLoXz",
        "outputId": "2e5e44ad-c3ab-4e7e-df7c-274f9388460a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습용 데이터셋 다운로드\n",
        "* 데이터 셋: review comments of Google application\n",
        "\n",
        "\n",
        "> 감정 분류 모델의 일반적인 Open dataset은 뉴스 기사 등 문어체로 작성된 문장들이 대부분임. Google App store의 고객 리뷰 데이터는 구어체로 이루어져 있으며, 이는 본 프로젝트에서 사용하는 Reddit comments 데이터와 유사한 성격을 가짐. 따라서 해당 데이터셋을 이용해 BERT 모델을 학습시켜 테스트 데이터셋에 대한 성능을 향상시키고자 함. \n",
        "* 추후 더욱 적절한 데이터셋을 발견하면, 이를 반영하여 모델을 재학습시키고자 함.\n",
        "\n"
      ],
      "metadata": {
        "id": "E1mj_sv9L1Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 다운로드\n",
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHdar6u9Lygh",
        "outputId": "747d85ad-8036-44f0-e47f-fb1ea323d98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 84.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 다운로드\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2aYpYS1L1IG",
        "outputId": "054c2a92-7159-41b6-c02c-654924f0e981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "100% 7.17M/7.17M [00:00<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "s_9XnhnRNpIF",
        "outputId": "2c15fe4a-833b-40dd-f692-73293e1aded5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           userName                                          userImage  \\\n",
              "0     Andrew Thomas  https://lh3.googleusercontent.com/a-/AOh14GiHd...   \n",
              "1      Craig Haines  https://lh3.googleusercontent.com/-hoe0kwSJgPQ...   \n",
              "2     steven adkins  https://lh3.googleusercontent.com/a-/AOh14GiXw...   \n",
              "3  Lars Panzerbjørn  https://lh3.googleusercontent.com/a-/AOh14Gg-h...   \n",
              "4     Scott Prewitt  https://lh3.googleusercontent.com/-K-X1-YsVd6U...   \n",
              "\n",
              "                                             content  score  thumbsUpCount  \\\n",
              "0  Update: After getting a response from the deve...      1             21   \n",
              "1  Used it for a fair amount of time without any ...      1             11   \n",
              "2  Your app sucks now!!!!! Used to be good but no...      1             17   \n",
              "3  It seems OK, but very basic. Recurring tasks n...      1            192   \n",
              "4  Absolutely worthless. This app runs a prohibit...      1             42   \n",
              "\n",
              "  reviewCreatedVersion                   at  \\\n",
              "0             4.17.0.3  2020-04-05 22:25:57   \n",
              "1             4.17.0.3  2020-04-04 13:40:01   \n",
              "2             4.17.0.3  2020-04-01 16:18:13   \n",
              "3             4.17.0.2  2020-03-12 08:17:34   \n",
              "4             4.17.0.2  2020-03-14 17:41:01   \n",
              "\n",
              "                                        replyContent            repliedAt  \\\n",
              "0  According to our TOS, and the term you have ag...  2020-04-05 15:10:24   \n",
              "1  It sounds like you logged in with a different ...  2020-04-05 15:11:35   \n",
              "2  This sounds odd! We are not aware of any issue...  2020-04-02 16:05:56   \n",
              "3  We do offer this option as part of the Advance...  2020-03-15 06:20:13   \n",
              "4  We're sorry you feel this way! 90% of the app ...  2020-03-15 23:45:51   \n",
              "\n",
              "       sortOrder      appId  \n",
              "0  most_relevant  com.anydo  \n",
              "1  most_relevant  com.anydo  \n",
              "2  most_relevant  com.anydo  \n",
              "3  most_relevant  com.anydo  \n",
              "4  most_relevant  com.anydo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9170d31-0987-4a09-bfc3-bc61ce70516c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9170d31-0987-4a09-bfc3-bc61ce70516c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9170d31-0987-4a09-bfc3-bc61ce70516c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9170d31-0987-4a09-bfc3-bc61ce70516c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape  # 데이터셋 size 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmRpXv7ZNqwq",
        "outputId": "0bd22bbe-a50d-41b0-8961-de5137768188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()   # 데이터셋 정보 (type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD4wlZoINtyP",
        "outputId": "760b6329-218d-4e6c-c4d9-2736419257db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15746 entries, 0 to 15745\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   userName              15746 non-null  object\n",
            " 1   userImage             15746 non-null  object\n",
            " 2   content               15746 non-null  object\n",
            " 3   score                 15746 non-null  int64 \n",
            " 4   thumbsUpCount         15746 non-null  int64 \n",
            " 5   reviewCreatedVersion  13533 non-null  object\n",
            " 6   at                    15746 non-null  object\n",
            " 7   replyContent          7367 non-null   object\n",
            " 8   repliedAt             7367 non-null   object\n",
            " 9   sortOrder             15746 non-null  object\n",
            " 10  appId                 15746 non-null  object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score')    # 별점 당 개수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "Cp88TdqKN1dk",
        "outputId": "b6b7d234-4381-483c-9e4d-6750f7777606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'review score')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 745,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1~5 까지의 별점을 positive, netural, negative로 총 3가지 카테고리로 나눔\n",
        "# positive, netural, negative 세 가지 카테고리로 나누어 학습하는 것이 Sentiment analysis 모델의 특징\n",
        "# 감정을 더욱 세분화해 학습시키는 것은 emotion analysis 분야이며, 본 프로젝트에서 필요한 K 가중치 값을 구하기 위해서는 sentimental analysis 모델을 사용해야 함.\n",
        "\n",
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "metadata": {
        "id": "BY_euIX0N3rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "metadata": {
        "id": "2KqA48hcOcFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);\n",
        "\n",
        "# 감정을 세 가지 분류로 나눔"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "5XhfzL5WOdks",
        "outputId": "8620eecb-6c9d-4f0c-8e5e-2077c74a3468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 745,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리 (Data Preprocessing)\n",
        "\n"
      ],
      "metadata": {
        "id": "D6zOyY9IOldk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리에 필요한 tokenizer 모델 다운로드\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "sB1kPWLYOfzy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9bead08073664779988f300d0731297d",
            "98196384fe564ba1a0992fd9d7569669",
            "aa2945a62aa940389075c3c38f374144",
            "9a82568195a745088d2de0a3ad363e32",
            "e37a0181eb0749b8ba50734f731a7784",
            "cc4e081adb914f6da57bd1a481ca821f",
            "ea7aa5b0023d4890a8febfcd0f5bdbde",
            "8313b33bb0f04adaa999ee42931a9fcc",
            "0f5bf83183d840ff8d190df85acb2be8",
            "19eb518f9c39499f88c8dcde3a53e242",
            "37044ae54e7244eaa51926329f5c9182",
            "e0afb9732fe9475f9c8179128bd7fad6",
            "6b465ce27c464d31ae224484ae51be2d",
            "169a46af9a934b0a9ec3454ebe15c982",
            "701fb6ce990f4c719ad5be66d5f0f1f6",
            "ea2a6e4fef6b4a489036e9b5459957d5",
            "21e1e42081c4429db1c01910da68fef9",
            "58282b987fb6469d8b802a0477ad3083",
            "1673534369b84e7d8c7ce2da003578e5",
            "777d36f0d53a4cb5aed8a1f154fe2d79",
            "6d4e15063823493b9dae95bf72872a71",
            "3324f1e1de644438bff2847c91513422",
            "20df4dc2ee3b4727a82e2aac4dc7a579",
            "0e59ec612f7a48f4876d510cda1f7a23",
            "56f8aa5f7a7549dabe0d82d90414b73a",
            "7219cc54ff1c4c2fb210a93d3de73fba",
            "9da241bebb0646199eac0dd2704c94b1",
            "86bfc3ec61e844699ea2d3969e487b16",
            "42a683fcf1444fd5be0aca23f10a43fe",
            "851afc2618bf426ebba2444a9fb32063",
            "2e24bc2f094d429faccc6911581b8167",
            "08cdcc50f37748f99bb03b77931aa2d0",
            "8d3b427a7dbd473da9dc829d1cbbdacb"
          ]
        },
        "outputId": "7c2f1590-824d-48ee-d2b1-f7aa04dda628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bead08073664779988f300d0731297d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0afb9732fe9475f9c8179128bd7fad6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20df4dc2ee3b4727a82e2aac4dc7a579"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 문장으로 전처리 진행 후 결과 확인\n",
        "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n",
        "\n",
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85CYN06XO2E4",
        "outputId": "0890feba-f783-4fbd-d5cf-0e1f4da60cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
            "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
            "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# special token들은 따로 토큰화 진행. [SEP], [CLS], [PAD], [UNK]\n",
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-2r3ZDKO6xE",
        "outputId": "1b20bf7e-4556-4d21-d466-95e7881d43d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 102)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP0INvW5PIhQ",
        "outputId": "b3410e9a-6baf-44e1-bf61-3cf991fdaea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 101)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftSrcOcHPPjC",
        "outputId": "a1fa5bb2-57a4-47d3-8298-36629c068aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDvPw_A3PQmp",
        "outputId": "d38dfeeb-5120-4b61-8e02-4b43f1bd179f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 100)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding 진행\n",
        "\n",
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  # pad_to_max_length=True,\n",
        "  padding=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cfOBdydPQ4w",
        "outputId": "c1047af2-b9d0-41d8-b171-bc986fd2aab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2280: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T-dqT38PVOq",
        "outputId": "5bdcdcae-bbab-4953-beb4-b8f1b08a2ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
              "        1111,  123, 2277,  119,  102])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF7A685gPX8W",
        "outputId": "aabcd996-20a7-477c-a92f-cda0b6f2be2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_text 에 대한 토큰화 결과 확인\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4ssbzMJPZnG",
        "outputId": "76af09df-e48e-4d79-93ab-7dfed21a0fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'When',\n",
              " 'was',\n",
              " 'I',\n",
              " 'last',\n",
              " 'outside',\n",
              " '?',\n",
              " 'I',\n",
              " 'am',\n",
              " 'stuck',\n",
              " 'at',\n",
              " 'home',\n",
              " 'for',\n",
              " '2',\n",
              " 'weeks',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence Length 선택\n",
        "BERT 모델은 fixed-length sequences를 가지며, 이를 효과적으로 선택해야 함."
      ],
      "metadata": {
        "id": "W0N-CP1WPkHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df.content:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYfO2ZlSPwkj",
        "outputId": "2b64153e-1ef9-43be-e653-72272892256e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터의 모든 댓글들의 길이를 시각화하여 max_length를 선택\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "otsVXiHEPxMP",
        "outputId": "b6c7004c-d3ab-40ed-e34f-e929660ff49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 757,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이의 댓글은 128 token으로 이루어져 있으며, 여유를 두어 max length를 160으로 설정함\n",
        "MAX_LEN = 160"
      ],
      "metadata": {
        "id": "oowOOcZ8P6gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch 프레임워크를 사용해 데이터 셋을 가공하는 함수 작성"
      ],
      "metadata": {
        "id": "7n3lbig2QNDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "fjwJa-pzQFdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습을 위한 dataset split\n",
        "\n",
        "\n",
        "*   Train set\n",
        "*   Test set\n",
        "*   Validation set\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8OoczbikQXpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "TDpxLezyQYkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KneEuetuQU6z",
        "outputId": "d9200be8-1196-42b8-9ec6-c259c7029a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14171, 12), (787, 12), (788, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "metadata": {
        "id": "LiSYaAOoQuBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq4KYQteQyaG",
        "outputId": "dedbaa63-3f0c-42f0-e1ac-ea962fa33563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training data loader의 example batch를 확인"
      ],
      "metadata": {
        "id": "1ravZ2fIQ4ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe8ZNaB8Qyrj",
        "outputId": "21c9b679-9f90-4f51-a8d3-8011b57b89f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Classification with BERT and Hugging Face"
      ],
      "metadata": {
        "id": "r6_gU7BXRH5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning을 위해 Pretrained BERT 다운로드\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "\n",
        "# return_dict = False를 추가해야\n",
        "# last_hidden_state.shape와 pooled_output.shape 가 실행됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "2cee96ef883d436ea8d984aa1126f8e5",
            "d880ad38ac7142f0b8f2b23b0f688ab1",
            "3999fba07e2242c3a6be2913d2eec86b",
            "40b705d35f564a2fb6a0efa0224a18ec",
            "d376626d7f0e45138d78d2fa01b0b96f",
            "ed3175ca09414480b1f1c48f48c781f4",
            "24b8649914fe41adad872b50abaf6ef9",
            "d87b47d5d4de4e1e8a62c2925b5579b2",
            "cce9bee1bcf8415eab95865aa153dbe5",
            "ccab2b5d14584824bf3201412cf2aff7",
            "b626ce2f60fd4d668e1e8acb3740e2a1"
          ]
        },
        "id": "YkktiNjwRFqi",
        "outputId": "af893da1-fd04-46e7-fe89-2ee86a0cef22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cee96ef883d436ea8d984aa1126f8e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "metadata": {
        "id": "5pcnARIURVRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state.shape\n",
        "bert_model.config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05caP2prRZ38",
        "outputId": "fd8a9822-ed7a-4b3e-a15f-4e50394ea610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "58uBn3bHRcUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnQYHH56RhKA",
        "outputId": "0d690df7-9450-4e18-8b94-223806520a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz6YJ6yORmxc",
        "outputId": "65e7acb8-1fa7-410a-8363-94d8b3c163d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4jJECrxRnjQ",
        "outputId": "51a2f9bb-1435-4fcd-ee64-9be4b918bd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2332, 0.4717, 0.2951],\n",
              "        [0.2219, 0.3612, 0.4168],\n",
              "        [0.3589, 0.2427, 0.3984],\n",
              "        [0.2221, 0.3218, 0.4561],\n",
              "        [0.5762, 0.2056, 0.2181],\n",
              "        [0.2249, 0.4422, 0.3329],\n",
              "        [0.2750, 0.3181, 0.4069],\n",
              "        [0.3732, 0.2454, 0.3813],\n",
              "        [0.3927, 0.1892, 0.4181],\n",
              "        [0.3349, 0.1948, 0.4703],\n",
              "        [0.3043, 0.2263, 0.4695],\n",
              "        [0.3710, 0.1894, 0.4396],\n",
              "        [0.2090, 0.4449, 0.3462],\n",
              "        [0.3396, 0.2594, 0.4010],\n",
              "        [0.3456, 0.2260, 0.4284],\n",
              "        [0.1500, 0.3302, 0.5198]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "AEECvV5ERqea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EPOCHS = 1\n",
        "EPOCHS = 50    # 우선 EPOCH 1을 실행해서 제대로 학습이 되는지 확인 후, 끊기지 않는 서버를 이용해 EPOCH 수를 늘려 학습할 것.\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "lKbAlNhzRpO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9524699c-e7bc-4bfe-f1f0-ee16bfe5c3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "rvxUoLm5V5sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning을 위해 추천하는 hyperparameters:\n",
        "\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "> batch size를 높일 수록 훈련 시간은 줄어들지만, 정확도는 낮아질 것이다. (적절한 batch size를 골라 학습시킬 것)\n",
        "\n"
      ],
      "metadata": {
        "id": "3d9c8G8oSBZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "3B8h61xoShj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "TA9SlmQRSrjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  # best_model_state 저장\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "id": "6uNED6JgStV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93af69ed-3692-49ae-bf7b-993cd6d0e59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7610502742550443 accuracy 0.6494954484510621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6243341246247291 accuracy 0.7318932655654384\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.457142828486473 accuracy 0.8251358408016372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5904040387272835 accuracy 0.8195679796696316\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.27547128931156717 accuracy 0.9098863876931762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6395489533524961 accuracy 0.8487928843710293\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.18435545585580215 accuracy 0.9479218121515772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6765362776722759 accuracy 0.8716645489199493\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1441417371292607 accuracy 0.9623174087926046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8028598460601643 accuracy 0.8678526048284626\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11688709664624315 accuracy 0.9697269070637218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8900496917858254 accuracy 0.8716645489199493\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10531125347083092 accuracy 0.9726201397219675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.867767147271661 accuracy 0.8576874205844981\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08361787687636332 accuracy 0.976642438783431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8367680278554326 accuracy 0.8729351969504447\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07904317308936079 accuracy 0.979676804742079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9143628850666573 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07202541191584778 accuracy 0.9796062380918779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9204406365426258 accuracy 0.8742058449809403\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0689420515817992 accuracy 0.9810881377461013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9067248465912416 accuracy 0.8729351969504447\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06166520140134915 accuracy 0.982781737350928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.961503086281009 accuracy 0.8678526048284626\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.046597848282425795 accuracy 0.985251570107967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9677655102900462 accuracy 0.8805590851334181\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.058257762402098054 accuracy 0.9828523040011291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0586845241019909 accuracy 0.8703939008894537\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.053663757572182925 accuracy 0.9843342036553525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9734974458639044 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04426799210694537 accuracy 0.9858161033095759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.108349938457104 accuracy 0.8691232528589581\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03917173659904683 accuracy 0.9866629031119893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0970887158705591 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.051504295211887534 accuracy 0.9846870369063581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0812852560344617 accuracy 0.8716645489199493\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0402625628674812 accuracy 0.9873685696140004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0561721643686905 accuracy 0.8843710292249047\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03729061054985222 accuracy 0.987721402865006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1371397050965606 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03135529667523776 accuracy 0.9884270693670172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1631306392949774 accuracy 0.8653113087674714\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03409165850904999 accuracy 0.9879331028156094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0276273205089819 accuracy 0.8843710292249047\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03726404322712511 accuracy 0.9884976360172183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0354195665473527 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.035786271848415506 accuracy 0.9882153694164139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0672130805810593 accuracy 0.8831003811944091\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02940474729875572 accuracy 0.9893444358196317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1280409696013884 accuracy 0.8792884371029225\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.028178842593975215 accuracy 0.9893444358196317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1168659162453696 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03185037519815893 accuracy 0.9887093359678216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1305424631610732 accuracy 0.878017789072427\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02936052251336179 accuracy 0.9890621692188272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.14633790953274 accuracy 0.8805590851334181\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02752738476062197 accuracy 0.9899089690212406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1819840587921135 accuracy 0.8742058449809403\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.024920546974480824 accuracy 0.9900501023216428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1307577158354798 accuracy 0.8805590851334181\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02586250979738065 accuracy 0.9899089690212406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.372374916217832 accuracy 0.855146124523507\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.025195252224102762 accuracy 0.9904029355726484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.205572769979699 accuracy 0.8716645489199493\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02455401955440509 accuracy 0.9908263354738551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2126509300011277 accuracy 0.8742058449809403\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0291937666866947 accuracy 0.9891327358690284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2342494640606674 accuracy 0.8742058449809403\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.023573581600550873 accuracy 0.9904735022228495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2427350742879752 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.021429927451336955 accuracy 0.9910380354244585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2712545728414262 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02137086183441213 accuracy 0.9909674687742573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2600173176380667 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.020319240783445415 accuracy 0.9908263354738551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2275345550366183 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.023231874067485468 accuracy 0.9902618022722461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2329077981662704 accuracy 0.878017789072427\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.021087153578525142 accuracy 0.990755768823654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2497638058465055 accuracy 0.8805590851334181\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02163592671693624 accuracy 0.9908263354738551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.244604303293454 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022275773195130216 accuracy 0.9906146355232518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2268389098288934 accuracy 0.8792884371029225\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02022350868405091 accuracy 0.9914614353256651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2450747845695695 accuracy 0.8831003811944091\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022329739416740983 accuracy 0.9911086020746596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2573136545487886 accuracy 0.8792884371029225\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019567569937371382 accuracy 0.9914614353256651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2348102792469127 accuracy 0.8818297331639137\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02108740315007866 accuracy 0.990755768823654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2693155664754614 accuracy 0.8742058449809403\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.018744053981839502 accuracy 0.9921671018276763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2418539181369852 accuracy 0.8818297331639137\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.018950036781841487 accuracy 0.991390868675464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2676533129207201 accuracy 0.878017789072427\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01930910113679431 accuracy 0.9914614353256651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2534636723707717 accuracy 0.8792884371029225\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019951255766289304 accuracy 0.9910380354244585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.246802536326777 accuracy 0.8818297331639137\n",
            "\n",
            "CPU times: user 3h 32min 32s, sys: 1h 46min 40s, total: 5h 19min 12s\n",
            "Wall time: 5h 20min 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(history['train_acc'], label='train accuracy')\n",
        "# plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "# plt.title('Training history')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend()\n",
        "# plt.ylim([0, 1]);"
      ],
      "metadata": {
        "id": "14jS1bqCSx-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained 모델을 사용하는 방법"
      ],
      "metadata": {
        "id": "iiPD4bFES1ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 시간이 너무 오래 걸려서 pt 모델 가져와서 감정분류 진행함\n",
        "# 학습을 원하는 경우, 위 코드대로 학습시키면 됨\n",
        "\n",
        "# !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA"
      ],
      "metadata": {
        "id": "yYrejuVPTFGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = SentimentClassifier(len(class_names))\n",
        "# model.load_state_dict(torch.load('best_model_state.bin'), strict=False) # strict=False 빼면 오류 발생\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "27hIZg9STJdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "MUATHCOJUH3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NUsUwxwTLcn",
        "outputId": "a8b18ff3-78c5-464d-99f4-aa0b40ca8052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.897208121827411"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "u-oHRthRULh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJokeffhUNb4",
        "outputId": "30b988db-a0d8-43be-bdd8-a8b3c546f86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 분류 정확도 출력 (모델 성능 출력)\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO67_nQCUPpA",
        "outputId": "d1075c5e-d0eb-4500-eb98-864d3b550bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.94      0.87      0.90       245\n",
            "     neutral       0.83      0.89      0.86       254\n",
            "    positive       0.92      0.93      0.93       289\n",
            "\n",
            "    accuracy                           0.90       788\n",
            "   macro avg       0.90      0.90      0.90       788\n",
            "weighted avg       0.90      0.90      0.90       788\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 정확도를 시각화\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "l6nsHpf6UUpG",
        "outputId": "66f2e749-3586-4c25-ee90-7941c87c4822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 725,
              "height": 516
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 및 테스트 결과 예시 출력\n",
        "idx = 2\n",
        "\n",
        "review_text = y_review_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_names,\n",
        "  'values': y_pred_probs[idx]\n",
        "})"
      ],
      "metadata": {
        "id": "j5-45X0gUaNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(wrap(review_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_names[true_sentiment]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NRMnAXhUdOT",
        "outputId": "23c1209a-cfa6-41be-c990-7f715991d924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I used to use Habitica, and I must say this is a great step up. I'd\n",
            "like to see more social features, such as sharing tasks - only one\n",
            "person has to perform said task for it to be checked off, but only\n",
            "giving that person the experience and gold. Otherwise, the price for\n",
            "subscription is too steep, thus resulting in a sub-perfect score. I\n",
            "could easily justify $0.99/month or eternal subscription for $15. If\n",
            "that price could be met, as well as fine tuning, this would be easily\n",
            "worth 5 stars.\n",
            "\n",
            "True sentiment: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 크롤링한 Reddit bitcoin Daily Discussion comments에 대한 감정 분류 진행"
      ],
      "metadata": {
        "id": "G4YMRzgcULJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_result = []\n",
        "\n",
        "for j in df_comments['comments']:\n",
        "  review_text = j\n",
        "  # tokenizer을 사용해 댓글 문장을 encode함\n",
        "  encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        "  )\n",
        "  input_ids = encoded_review['input_ids'].to(device)\n",
        "  attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "  output = model(input_ids, attention_mask)\n",
        "  _, prediction = torch.max(output, dim=1)\n",
        "\n",
        "  # print(f'Review text: {review_text}')\n",
        "  sentiment_result.append(class_names[prediction])\n",
        "  print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp45CNyrUppF",
        "outputId": "2af2aa53-1646-410b-d48d-896edd4dc967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : positive\n",
            "Sentiment  : negative\n",
            "Sentiment  : positive\n",
            "Sentiment  : neutral\n",
            "Sentiment  : neutral\n",
            "Sentiment  : negative\n",
            "Sentiment  : negative\n",
            "Sentiment  : neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKo2tJwWWMKu",
        "outputId": "a0b00328-3dc8-4841-aae0-f0fa22d6f3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'neutral']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments.insert(2, 'sentiment', sentiment_result)  # 데이터프레임에 sentiment 결과 추가\n",
        "df_comments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zoSph9J8Wxk2",
        "outputId": "93bd2aac-ba98-4772-bc7a-2613ca3f80dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           date                                           comments sentiment\n",
              "0    2022-05-10  Bought a certain shitcoin a month ago that’s n...  negative\n",
              "1    2022-05-10  The cnbc article on how 40% of Bitcoin investo...  negative\n",
              "2    2022-05-10         If you woke up holding BTC…..you winning 🏆   neutral\n",
              "3    2022-05-10                                *\"Round 2, fight!\"*   neutral\n",
              "4    2022-05-10   Just stacked some more cheap sats. Life is good.  positive\n",
              "..          ...                                                ...       ...\n",
              "227  2022-05-10  Are you calling me gay? That's not very 2022 like   neutral\n",
              "228  2022-05-10                 Tech moves fast but people do not.   neutral\n",
              "229  2022-05-10  Bitcoin is not static, it's a hotbed of techno...  negative\n",
              "230  2022-05-10  I bet you're fun at parties. Back to buttcoin ...  negative\n",
              "231  2022-05-10          Show me your gains bro. I need gains porn   neutral\n",
              "\n",
              "[232 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83823d03-ec68-4f4a-876f-f5b9e262a80d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comments</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Bought a certain shitcoin a month ago that’s n...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>The cnbc article on how 40% of Bitcoin investo...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>If you woke up holding BTC…..you winning 🏆</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>*\"Round 2, fight!\"*</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Just stacked some more cheap sats. Life is good.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Are you calling me gay? That's not very 2022 like</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Tech moves fast but people do not.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Bitcoin is not static, it's a hotbed of techno...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>I bet you're fun at parties. Back to buttcoin ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Show me your gains bro. I need gains porn</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83823d03-ec68-4f4a-876f-f5b9e262a80d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83823d03-ec68-4f4a-876f-f5b9e262a80d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83823d03-ec68-4f4a-876f-f5b9e262a80d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 계산\n",
        "K_sum = 0   # 가중치 합 저장\n",
        "neutral_count = 0 # 감정 별 개수 저장\n",
        "positive_count = 0\n",
        "negative_count = 0\n",
        "\n",
        "for s in df_comments['sentiment']:\n",
        "  if s == 'neutral':    # netural = 0.5\n",
        "    K_sum += 0.5\n",
        "    neutral_count+=1\n",
        "  elif s == 'positive':\n",
        "    K_sum += 1          # positive = 1\n",
        "    positive_count+=1\n",
        "  else:               \n",
        "    K_sum += 0          # negative = 0\n",
        "    negative_count+=1\n",
        "\n",
        "K_weight = K_sum / len(sentiment_result)\n",
        "K_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gWAkGW9W5CG",
        "outputId": "bd3e795b-d67a-41a2-974f-219fdde3fb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46120689655172414"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments.insert(3, 'K_weight', K_weight)\n",
        "df_comments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PfYqu126XVJr",
        "outputId": "24dbfb7a-b251-4dae-ae3e-cadbcba82ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           date                                           comments sentiment  \\\n",
              "0    2022-05-10  Bought a certain shitcoin a month ago that’s n...  negative   \n",
              "1    2022-05-10  The cnbc article on how 40% of Bitcoin investo...  negative   \n",
              "2    2022-05-10         If you woke up holding BTC…..you winning 🏆   neutral   \n",
              "3    2022-05-10                                *\"Round 2, fight!\"*   neutral   \n",
              "4    2022-05-10   Just stacked some more cheap sats. Life is good.  positive   \n",
              "..          ...                                                ...       ...   \n",
              "227  2022-05-10  Are you calling me gay? That's not very 2022 like   neutral   \n",
              "228  2022-05-10                 Tech moves fast but people do not.   neutral   \n",
              "229  2022-05-10  Bitcoin is not static, it's a hotbed of techno...  negative   \n",
              "230  2022-05-10  I bet you're fun at parties. Back to buttcoin ...  negative   \n",
              "231  2022-05-10          Show me your gains bro. I need gains porn   neutral   \n",
              "\n",
              "     K_weight  \n",
              "0    0.461207  \n",
              "1    0.461207  \n",
              "2    0.461207  \n",
              "3    0.461207  \n",
              "4    0.461207  \n",
              "..        ...  \n",
              "227  0.461207  \n",
              "228  0.461207  \n",
              "229  0.461207  \n",
              "230  0.461207  \n",
              "231  0.461207  \n",
              "\n",
              "[232 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51a32fa4-e3a2-4bb0-8b75-449aebe48cb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>comments</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>K_weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Bought a certain shitcoin a month ago that’s n...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>The cnbc article on how 40% of Bitcoin investo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>If you woke up holding BTC…..you winning 🏆</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>*\"Round 2, fight!\"*</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Just stacked some more cheap sats. Life is good.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Are you calling me gay? That's not very 2022 like</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Tech moves fast but people do not.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Bitcoin is not static, it's a hotbed of techno...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>I bet you're fun at parties. Back to buttcoin ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>2022-05-10</td>\n",
              "      <td>Show me your gains bro. I need gains porn</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.461207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51a32fa4-e3a2-4bb0-8b75-449aebe48cb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51a32fa4-e3a2-4bb0-8b75-449aebe48cb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51a32fa4-e3a2-4bb0-8b75-449aebe48cb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV 결과 저장 및 댓글 감정 분류에 대한 결과 시각화"
      ],
      "metadata": {
        "id": "jZe8gtM2Xn_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# csv 파일 저장할 경로를 환경에 알맞게 변경하기\n",
        "import csv\n",
        "PATH = '/content/drive/MyDrive/윤수림/'+date+'_result2.csv'\n",
        "df_comments.to_csv(PATH)"
      ],
      "metadata": {
        "id": "zSEi0VIkXgqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('neutral 개수: ', neutral_count)\n",
        "print('\\npositive 개수: ', positive_count)\n",
        "print('negative 개수: ', negative_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK45UOkiXmXv",
        "outputId": "e974fdb7-e798-4dd3-81ef-7cc74b8b5dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral 개수:  88\n",
            "\n",
            "positive 개수:  63\n",
            "negative 개수:  81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(3)\n",
        "sentiments = ['negative', 'neutral', 'positive']\n",
        "values = [negative_count, neutral_count, positive_count]\n",
        "\n",
        "plt.bar(x, values, color=['r', 'g', 'b'])\n",
        "plt.xticks(x, sentiments)\n",
        "plt.title('Number of sentiments', fontsize=20)\n",
        "plt.xlabel('Sentiments')\n",
        "plt.ylabel('Number')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "qGKpfYeRXlFt",
        "outputId": "d6eb53ab-4411-4541-d50d-b577aa41c72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 728,
              "height": 511
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9_RpuP2JObUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}